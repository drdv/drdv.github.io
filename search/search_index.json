{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to my page!","text":"<p>I have worked as a senior data scientist at Kelkoo (France) and a data scientist/software engineer at ProbaYes (France). I obtained a Ph. D. degree in 2006 from Tohoku University (Japan) and a M. Sc. diploma in 1999 from the Technical University-Sofia (Bulgaria). I have been a research scientist at INRIA - Grenoble (France), and a research scientist / lecturer at AASS \u00d6rebro University (Sweden).</p>"},{"location":"#contact","title":"Contact","text":"<ul> <li>email: mail.mitko@gmail.com</li> </ul>"},{"location":"cv/","title":"Curriculum vitae","text":"<p>I was born in Sofia, Bulgaria (20.11.1975)</p>"},{"location":"cv/#professional-experience","title":"Professional experience","text":"2021.03 - 2024.05: Kelkoo <p>senior data scientist (science team)</p> researchcoding <ul> <li>machine learning and operations research for online bidding</li> <li>traffic / resource optimization</li> <li>modeling of merchant-publisher interaction (handling of sparse data)</li> <li>multi-objective formulations for margin optimization</li> </ul> <ul> <li><code>python</code><ul> <li>development of company standards for code quality and documentation</li> <li>design/maintenance of common libraries</li> <li>put in place a local PyPi server</li> </ul> </li> <li><code>scala</code><ul> <li>production quality code</li> </ul> </li> <li><code>spark</code><ul> <li>production quality code</li> </ul> </li> <li>working with <code>HDFS</code>, <code>YARN</code></li> <li>in charge of scientific and project documentation</li> </ul> 2017.09 - 2021.03: ProbaYes <p>data scientist/software engineer</p> researchcoding <ul> <li> <p>machine learning applied to various domains</p> <ul> <li>fault detection</li> <li>image classification (deep learning)</li> <li>deep reinforcement learning for trajectory generation</li> <li>camera calibration</li> </ul> </li> <li> <p>causal analysis</p> </li> <li>concurrent HMM for behavior detection</li> <li>graph analysis</li> <li>time series analysis</li> <li>evaluation of fuzzy controllers</li> <li>development of strategies for fast evaluation of boolean functions<ul> <li>using techniques employed in compiler optimization</li> <li>application: quantum computing</li> </ul> </li> </ul> <ul> <li><code>python</code><ul> <li>delivered code for many projects to clients (on Linux/Windows)</li> </ul> </li> <li><code>C++</code><ul> <li>worked as consultant/contractor on code base of Valeo</li> <li>design/maintenance of <code>CMake</code> based build systems</li> </ul> </li> <li><code>rust</code><ul> <li>developed rocket simulator for MBDA</li> </ul> </li> </ul>"},{"location":"cv/#research-experience","title":"Research experience","text":"2012.10 - 2015.12: INRIA Rh\u00f4ne-Alpes <p>research scientist (BIPOP team)</p> researchcoding <ul> <li>fast and reliable solution of lexicographic optimization problems applied to robot control<ul> <li>implementation of solver in <code>C++</code></li> <li>applied to real-world robot safety</li> </ul> </li> <li>nonlinear model predictive control</li> <li>robust control for safe locomotion</li> <li>minimum-time control</li> <li>simulation of mechanical systems</li> <li>numerical analysis</li> </ul> <ul> <li><code>c++</code><ul> <li>implemented an active-set solver for lexicographic least-squares problems</li> </ul> </li> <li><code>matlab</code></li> </ul> 2007.12 - 2012.09: \u00d6rebro University <p>research scientist/lecturer (Mobile Robotics and Olfaction Lab at AASS)</p> researchteaching <ul> <li>model predictive control applied to walking robots</li> <li>robotic grasping</li> <li>motion planning for nonholonomic vehicles</li> <li>combining task and motion planning for robotic manipulators</li> </ul> <ul> <li>control of linear &amp; nonlinear systems</li> <li>simulation of multibody systems</li> <li>introduction to optimization</li> </ul> 2006.12 - 2007.12: INRIA Rh\u00f4ne-Alpes <p>research scientist (BIPOP team)</p> <ul> <li>model predictive control for biped robot walking motion generation</li> </ul>"},{"location":"cv/#education","title":"Education","text":"2003.04 - 2006.03: Tohoku University <ul> <li>Space Robotics Laboratory Department of Aerospace Engineering</li> <li>degree: Ph.D. in aerospace engineering</li> <li>topic: dynamics and control of space manipulators during a satellite capturing operation</li> <li>advisor: Prof. Kazuya Yoshida</li> <li>awards: Scholarship from the Japanese Ministry of Education MONBU-SHYO (2003.04 - 2006.03)</li> </ul> 2003.04 - 2006.03: Hirosaki University <ul> <li>Department of Mechanical Science and Engineering</li> <li>advisor: Prof. Dragomir Nenchev</li> <li>awards: Scholarship from Hirosaki University (2002.10 - 2003.03)</li> </ul> 1994.09 - 2001.09: Technical University - Sofia <ul> <li>Faculty of Automatics</li> <li>degrees: M.Sc. in robotics (1999.09), B.A. in electrical engineering (1997.09)</li> <li>advisor: Prof. Veselin Pavlov (M.Sc. thesis)</li> <li>I decided to move to Japan after having spent two years as a doctoral student</li> </ul>"},{"location":"cv/#publications","title":"Publications","text":"<p>Link to my publications</p>"},{"location":"cv/#languages","title":"Languages","text":"<ul> <li>Bulgarian (native)</li> <li>English (fluent)</li> <li>Japanese (conversational)</li> <li>Russian (basic)</li> <li>French (beginner)</li> </ul>"},{"location":"gpg/","title":"My public GPG key","text":"<p>download</p> curl -O https://drdv.github.io/snippets/gpg.pub<pre><code>-----BEGIN PGP PUBLIC KEY BLOCK-----\n\nmDMEZ4szzRYJKwYBBAHaRw8BAQdAJjrykbG2D6n2LBlhCmeODMK/GIcZpWSmUiJ2\nLX+Qmgi0J0RpbWl0YXIgRGltaXRyb3YgPG1haWwubWl0a29AZ21haWwuY29tPoiZ\nBBMWCgBBFiEEErdNhqK+4h4XF1NTYUFgCHHD7McFAmeLM80CGwMFCQHhM4AFCwkI\nBwICIgIGFQoJCAsCBBYCAwECHgcCF4AACgkQYUFgCHHD7McCdAEAmhVwjgSMW2JU\napK0TwYTPMiE0jbe2P/55pzPteR8ydEBAPk9IhzJenDl++55JYSIDAFJjBk6yLME\nSy+piLfKGNcHuDgEZ4szzRIKKwYBBAGXVQEFAQEHQBKF6/VOIunkQBE8Vb5q7eAC\nisQKuobFcQK4CJVo5ao5AwEIB4h+BBgWCgAmFiEEErdNhqK+4h4XF1NTYUFgCHHD\n7McFAmeLM80CGwwFCQHhM4AACgkQYUFgCHHD7Meo8wEAi8AI0xEGpSQ2075/haFj\n+wfMmqCi+EPTkiljCqEzJoABAI/Og0ElF0ewuvs0fdXcfYb6F4yf8+z2Ey/nAUfM\n5tgG\n=BGhX\n-----END PGP PUBLIC KEY BLOCK-----\n</code></pre> gpg --show-keys gpg.pub<pre><code>pub   ed25519 2025-01-18 [SC] [expires: 2026-01-18]\n      12B74D86A2BEE21E171753536141600871C3ECC7\nuid                      Dimitar Dimitrov &lt;mail.mitko@gmail.com&gt;\nsub   cv25519 2025-01-18 [E] [expires: 2026-01-18]\n</code></pre>"},{"location":"publications/","title":"Publications","text":""},{"location":"publications/#2016","title":"2016","text":"Efficient resolution of potentially conflicting linear constraints in robotics <p>manuscript</p> authorsbibtex <ul> <li>Dimitar Dimitrov</li> <li>Alexander Sherikov</li> <li>Pierre-Brice Wieber</li> </ul> <ul> <li>not published</li> </ul> Geometric and numerical aspects of redundancy <p>preprint</p> authorsbibtex <ul> <li>Pierre-Brice Wieber</li> <li>Adrien Escande</li> <li>Dimitar Dimitrov</li> <li>Alexander Sherikov</li> </ul> <pre><code>@incollection {Wieber.2016,\n author     = {Wieber, Pierre-Brice and Escande, Adrien and Dimitrov, Dimitar and Sherikov, Alexander},\n title      = {Geometric and numerical aspects of redundancy},\n editor     = {J. P. Laumond et al.},\n booktitle  = {Geometric and Numerical Foundations of Movements},\n publisher  = {Springer-Verlag},\n pages      = {67--85},\n year       = 2016}\n</code></pre> Safe navigation strategies for a biped robot walking in a crowd <p>preprint video</p> authorsbibtex <ul> <li>Nestor Bohorquez</li> <li>Alexander Sherikov</li> <li>Dimitar Dimitrov</li> <li>Pierre-Brice Wieber</li> </ul> <pre><code>@inproceedings{Bohorquez.2016,\n author     = {Bohorquez, Nestor and Sherikov, Alexander and Dimitrov, Dimitar and Wieber, Pierre-Brice},\n title      = {Safe navigation strategies for a biped robot walking in a crowd},\n booktitle  = {IEEE-RAS International Conference on Humanoid Robots (Humanoids)},\n pages      = {379--386},\n year       = 2016}\n</code></pre> A newton method with always feasible iterates for nonlinear model predictive control of walking in a multi-contact situation <p>preprint video</p> authorsbibtex <ul> <li>Diana Serra</li> <li>Camille Brasseur</li> <li>Alexander Sherikov</li> <li>Dimitar Dimitrov</li> <li>Pierre-Brice Wieber</li> </ul> <pre><code>@inproceedings{Serra.2016,\n author     = {Serra, Diana and Brasseur, Camille and Sherikov, Alexander and Dimitrov, Dimitar and Wieber, Pierre-Brice},\n title      = {A newton method with always feasible iterates for nonlinear model predictive control of walking in a multi-contact situation},\n booktitle  = {IEEE-RAS International Conference on Humanoid Robots (Humanoids)},\n pages      = {932--937},\n year       = 2016}\n</code></pre> A hierarchical approach to minimum-time control of industrial robots <p>preprint</p> authorsbibtex <ul> <li>Saed Al Homsi</li> <li>Alexander Sherikov</li> <li>Dimitar Dimitrov</li> <li>Pierre-Brice Wieber</li> </ul> <pre><code>@inproceedings{Holmsi.2016,\n author     = {Al~Homsi, Saed and Sherikov, Alexander and Dimitrov, Dimitar and Wieber, Pierre-Brice},\n title      = {A hierarchical approach to minimum-time control of industrial robots},\n booktitle  = {IEEE International Conference on Robotics and Automation (ICRA)},\n pages      = {2368--2374},\n year       = 2016}\n</code></pre>"},{"location":"publications/#2015","title":"2015","text":"Autonomous transport vehicles: where we are and what is missing <p>paper</p> authorsbibtex <ul> <li>Henrik Andreasson</li> <li>Abdelbaki Bouguerra</li> <li>Marcello Cirillo</li> <li>Dimitar Dimitrov</li> <li>Dimiter Driankov</li> <li>Lars Karlsson</li> <li>Achim J. Lilienthal</li> <li>Federico Pecora</li> <li>Jari Saarinen</li> <li>Alexander Sherikov</li> <li>Todor Stoyanov</li> </ul> <pre><code>@article      {Andreasson.2015,\n author     = {Andreasson, Henrik and Bouguerra, Abdelbaki and Cirillo, Marcello and Dimitrov, Dimitar and Driankov, Dimiter and Karlsson, Lars and et al.},\n title      = {Autonomous transport vehicles: where we are and what is missing},\n journal    = {IEEE Robotics and Automation Magazine (IEEE-RAM)},\n volume     = {22},\n number     = {1},\n pages      = {64--75},\n year       = 2015}\n</code></pre> Model predictive motion control based on generalized dynamical movement primitives <p>preprint</p> authorsbibtex <ul> <li>Robert Krug</li> <li>Dimitar Dimitrov</li> </ul> <pre><code>@article      {Krug.2015,\n author     = {Krug, Robert and Dimitrov, Dimitar},\n title      = {Model predictive motion control based on generalized dynamical movement primitives},\n journal    = {Journal of Intelligent \\&amp; Robotic Systems},\n volume     = {77},\n number     = {1},\n pages      = {17--35},\n year       = 2015}\n</code></pre> Balancing a humanoid robot with a prioritized contact force distribution <p>preprint video</p> authorsbibtex <ul> <li>Alexander Sherikov</li> <li>Dimitar Dimitrov</li> <li>Pierre-Brice Wieber</li> </ul> <pre><code>@inproceedings{Sherikov.2015,\n author     = {Sherikov, Alexander and Dimitrov, Dimitar and Wieber, Pierre-Brice},\n title      = {Balancing a humanoid robot with a prioritized contact force distribution},\n booktitle  = {IEEE-RAS International Conference on Humanoid Robots (Humanoids)},\n pages      = {223--228},\n year       = 2015}\n</code></pre> A robust linear MPC approach to online generation of 3D biped walking motion <p>preprint video</p> authorsbibtex <ul> <li>Camille Brasseur</li> <li>Alexander Sherikov</li> <li>Cyrille Collette</li> <li>Dimitar Dimitrov</li> <li>Pierre-Brice Wieber</li> </ul> <pre><code>@inproceedings{Brasseur.2015,\n author     = {Brasseur, Camille and Sherikov, Alexander and Collette, Cyrille and Dimitrov, Dimitar and Wieber, Pierre-Brice},\n title      = {A robust linear MPC approach to online generation of 3D biped walking motion},\n booktitle  = {IEEE-RAS International Conference on Humanoid Robots (Humanoids)},\n pages      = {595--601},\n year       = 2015}\n</code></pre>"},{"location":"publications/#2014","title":"2014","text":"Efficiently combining task and motion planning using geometric constraints <p>preprint</p> authorsbibtex <ul> <li>Fabien Lagriffoul</li> <li>Dimitar Dimitrov</li> <li>Julien Bidot</li> <li>Alessandro Saffiotti</li> <li>Lars Karlsson</li> </ul> <pre><code>@article      {Lagriffoul.2014,\n author     = {Lagriffoul, Fabien and Dimitrov, Dimitar and Bidot, Julien and Saffiotti, Alessandro and Karlsson, Lars},\n title      = {Efficiently combining task and motion planning using geometric constraints},\n journal    = {The International Journal of Robotics Research},\n volume     = {33},\n number     = {14},\n pages      = {1726--1747},\n year       = 2014}\n</code></pre> Whole body motion controller with long-term balance constraints <p>preprint video</p> authorsbibtex <ul> <li>Alexander Sherikov</li> <li>Dimitar Dimitrov</li> <li>Pierre-Brice Wieber</li> </ul> <pre><code>@inproceedings{Sherikov.2014,\n author     = {Sherikov, Alexander and Dimitrov, Dimitar and Wieber, Pierre-Brice},\n title      = {Whole body motion controller with long-term balance constraints},\n booktitle  = {IEEE-RAS International Conference on Humanoid Robots (Humanoids)},\n pages      = {444--450},\n year       = 2014}\n</code></pre> Multi-objective control of robots <p>preprint</p> authorsbibtex <ul> <li>Dimitar Dimitrov</li> <li>Pierre-Brice Wieber</li> <li>Adrien Escande</li> </ul> <pre><code>@article      {Dimitrov.2014,\n author     = {Dimitrov, Dimitar and Wieber, Pierre-Brice and Escande, Adrien},\n title      = {Multi-objective control of robots},\n journal    = {Journal of the Robotics Society of Japan},\n volume     = {32},\n number     = {6},\n pages      = {512--518},\n year       = 2014}\n</code></pre>"},{"location":"publications/#2013","title":"2013","text":"Representing movement primitives as implicit dynamical systems learned from multiple demonstrations <p>preprint</p> authorsbibtex <ul> <li>Robert Krug</li> <li>Dimitar Dimitrov</li> </ul> <pre><code>@inproceedings{Krug.2013,\n author     = {Krug, Robert and Dimitrov, Dimitar},\n title      = {Representing movement primitives as implicit dynamical systems learned from multiple demonstrations},\n booktitle  = {International Conference on Advanced Robotics (ICAR)},\n pages      = {1--8},\n year       = 2013}\n</code></pre>"},{"location":"publications/#2012","title":"2012","text":"Constraint propagation on interval bounds for dealing with geometric backtracking <p>preprint</p> authorsbibtex <ul> <li>Fabien Lagriffoul</li> <li>Dimitar Dimitrov</li> <li>Alessandro Saffiotti</li> <li>Lars Karlsson</li> </ul> <pre><code>@inproceedings{Lagriffoul.2012,\n author     = {Lagriffoul, Fabien and Dimitrov, Dimitar and Saffiotti, Alessandro and Karlsson, Lars},\n title      = {Constraint propagation on interval bounds for dealing with geometric backtracking},\n booktitle  = {IEEE/RSJ International Conference on Intelligent Robots and System (IROS)},\n pages      = {957--964},\n year       = 2012}\n</code></pre> On mission-dependent coordination of multiple vehicles under spatial and temporal constraints <p>preprint</p> authorsbibtex <ul> <li>Federico Pecora</li> <li>Marcello Cirillo</li> <li>Dimitar Dimitrov</li> </ul> <pre><code>@inproceedings{Pecora.2012,\n author     = {Pecora, Federico and Cirillo, Marcello and Dimitrov, Dimitar},\n title      = {On mission-dependent coordination of multiple vehicles under spatial and temporal constraints},\n booktitle  = {IEEE/RSJ International Conference on Intelligent Robots and System (IROS)},\n pages      = {5262--5269},\n year       = 2012}\n</code></pre> Independent contact regions based on a patch contact model <p>preprint</p> authorsbibtex <ul> <li>Krzysztof Charusta</li> <li>Robert Krug</li> <li>Dimitar Dimitrov</li> <li>Boyko Iliev</li> </ul> <pre><code>@inproceedings{Charusta.2012b,\n author     = {Charusta, Krzysztof and Krug, Robert and Dimitrov, Dimitar and Iliev, Boyko},\n title      = {Independent contact regions based on a patch contact model},\n booktitle  = {IEEE International Conference on Robotics and Automation (ICRA)},\n pages      = {4162--4169},\n year       = 2012}\n</code></pre> Generation of independent contact regions on objects reconstructed from noisy real-world range data <p>preprint</p> authorsbibtex <ul> <li>Krzysztof Charusta</li> <li>Robert Krug</li> <li>Todor Stoyanov</li> <li>Dimitar Dimitrov</li> <li>Boyko Iliev</li> </ul> <pre><code>@inproceedings{Charusta.2012a,\n author     = {Charusta, Krzysztof and Krug, Robert and Stoyanov, Todor and Dimitrov, Dimitar and Iliev, Boyko},\n title      = {Generation of independent contact regions on objects reconstructed from noisy real-world range data},\n booktitle  = {IEEE International Conference on Robotics and Automation (ICRA)},\n pages      = {1338--1344},\n year       = 2012}\n</code></pre> Mapping between different kinematic structures without absolute positioning during operation <p>paper</p> authorsbibtex <ul> <li>Erik Berglund</li> <li>Boyko Iliev</li> <li>Rainer Palm</li> <li>Robert Krug</li> <li>Krzysztof Charusta</li> <li>Dimitar Dimitrov</li> </ul> <pre><code>@article      {Berglund.2012,\n author     = {Berglund, Erik and Iliev, Boyko and Palm, Rainer and Krug, Robert and Charusta, Krzysztof and Dimitrov, Dimitar},\n title      = {Mapping between different kinematic structures without absolute positioning during operation},\n journal    = {Electronics Letters},\n volume     = {48},\n number     = {18},\n pages      = {1110--1112},\n year       = 2012}\n</code></pre>"},{"location":"publications/#2011","title":"2011","text":"A sparse model predictive control formulation for walking motion generation <p>preprint presentation errata implementation</p> authorsbibtex <ul> <li>Dimitar Dimitrov</li> <li>Alexander Sherikov</li> <li>Pierre-Brice Wieber</li> </ul> <pre><code>@inproceedings{Dimitrov.2011b,\n author     = {Dimitrov, Dimitar and Sherikov, Alexander and Wieber, Pierre-Brice},\n title      = {A sparse model predictive control formulation for walking motion generation},\n booktitle  = {IEEE/RSJ International Conference on Intelligent Robots and System (IROS)},\n pages      = {2292--2299},\n year       = 2011}\n</code></pre> Prioritized independent contact regions for form closure grasps <p>preprint</p> authorsbibtex <ul> <li>Robert Krug</li> <li>Dimitar Dimitrov</li> <li>Krzysztof Charusta</li> <li>Boyko Iliev</li> </ul> <pre><code>@inproceedings{Krug.2011,\n author     = {Krug, Robert and Dimitrov, Dimitar and Charusta, Krzysztof and Iliev, Boyko},\n title      = {Prioritized independent contact regions for form closure grasps},\n booktitle  = {IEEE/RSJ International Conference on Intelligent Robots and System (IROS)},\n pages      = {1797--1803},\n year       = 2011}\n</code></pre> Walking motion generation with online foot position adaptation based on - and -norm penalty formulations <p>preprint presentation</p> authorsbibtex <ul> <li>Dimitar Dimitrov</li> <li>Antonio Paolillo</li> <li>Pierre-Brice Wieber</li> </ul> <pre><code>@inproceedings{Dimitrov.2011a,\n author     = {Dimitrov, Dimitar and Paolillo, Antonio and Wieber, Pierre-Brice},\n title      = {Walking motion generation with online foot position adaptation based on $\\ell_1$- and $\\ell_\\infty$-norm penalty formulations},\n booktitle  = {IEEE International Conference on Robotics and Automation (ICRA)},\n pages      = {3523--3529},\n year       = 2011}\n</code></pre>"},{"location":"publications/#2010","title":"2010","text":"Online walking motion generation with automatic foot step placement <p>preprint</p> authorsbibtex <ul> <li>Andrei Herdt</li> <li>Holger Diedam</li> <li>Pierre-Brice Wieber</li> <li>Dimitar Dimitrov</li> <li>Katja Mombaur</li> <li>Moritz Diehl</li> </ul> <pre><code>@article      {Herdt.2010,\n author     = {Herdt, Andrei and Diedam, Holger and Wieber, Pierre-Brice and Dimitrov, Dimitar and Mombaur, Katja and Diehl, Moritz},\n title      = {Online walking motion generation with automatic foot step placement},\n journal    = {Advanced Robotics},\n volume     = {24},\n number     = {5--6},\n pages      = {719--737},\n year       = 2010}\n</code></pre> On the efficient computation of independent contact regions for force closure grasps <p>preprint</p> authorsbibtex <ul> <li>Robert Krug</li> <li>Dimitar Dimitrov</li> <li>Krzysztof Charusta</li> <li>Boyko Iliev</li> </ul> <pre><code>@inproceedings{Krug.2010,\n author     = {Krug, Robert and Dimitrov, Dimitar and Charusta, Krzysztof and Iliev, Boyko},\n title      = {On the efficient computation of independent contact regions for force closure grasps},\n booktitle  = {IEEE/RSJ International Conference on Intelligent Robots and System (IROS)},\n pages      = {586--591},\n year       = 2010}\n</code></pre> An optimized linear model predictive control solver <p>paper</p> authorsbibtex <ul> <li>Dimitar Dimitrov</li> <li>Pierre-Brice Wieber</li> <li>Olivier Stasse,</li> <li>Hans Joachim Ferreau</li> <li>Holger Diedam</li> </ul> <pre><code>@incollection {Dimitrov.2010,\n author     = {Dimitrov, Dimitar and Wieber, Pierre-Brice and Stasse, Olivier and Ferreau, Hans Joachim and Diedam, Holger},\n title      = {An optimized linear model predictive control solver},\n editor     = {Diehl, Moritz and Glineur, Fran\\c{c}ois and Jarlebring, Elias and Michiels, Wim},\n booktitle  = {Recent Advances in Optimization and its Applications in Engineering},\n publisher  = {Springer},\n pages      = {309--318},\n year       = 2010}\n</code></pre>"},{"location":"publications/#2009","title":"2009","text":"An optimized linear model predictive control solver for online walking motion generation <p>paper</p> authorsbibtex <ul> <li>Dimitar Dimitrov</li> <li>Pierre-Brice Wieber</li> <li>Olivier Stasse,</li> <li>Hans Joachim Ferreau</li> <li>Holger Diedam</li> </ul> <pre><code>@inproceedings{Dimitrov.2009,\n author     = {Dimitrov, Dimitar and Wieber, Pierre-Brice and Stasse, Olivier and Ferreau, Hans Joachim and Diedam, Holger},\n title      = {An optimized linear model predictive control solver for online walking motion generation},\n booktitle  = {IEEE International Conference on Robotics and Automation (ICRA)},\n pages      = {1171--1176},\n year       = 2009}\n</code></pre> Extraction of grasp related features by human dual-hand object exploration <p>paper</p> authorsbibtex <ul> <li>Krzysztof Charusta</li> <li>Dimitar Dimitrov</li> <li>Achim J. Lilienthal</li> <li>Boyko Iliev</li> </ul> <pre><code>@inproceedings{Charusta.2009,\n author     = {Charusta, Krzysztof and Dimitrov, Dimitar and Lilienthal, Achim J and Iliev, Boyko},\n title      = {Extraction of grasp related features by human dual-hand object exploration},\n booktitle  = {International Conference on Advanced Robotics (ICAR)},\n pages      = {122--127},\n year       = 2009}\n</code></pre>"},{"location":"publications/#2008","title":"2008","text":"Online walking gait generation with adaptive foot positioning through linear model predictive control <p>paper</p> authorsbibtex <ul> <li>Holger Diedam</li> <li>Dimitar Dimitrov</li> <li>Pierre-Brice Wieber</li> <li>Katja Mombaur</li> <li>Moritz Diehl</li> </ul> <pre><code>@inproceedings{Diedam.2008,\n author     = {Diedam, Holger and Dimitrov, Dimitar and Wieber, Pierre-Brice and Mombaur, Katja and Diehl, Moritz},\n title      = {Online walking gait generation with adaptive foot positioning through linear model predictive control},\n booktitle  = {IEEE/RSJ International Conference on Intelligent Robots and System (IROS)},\n pages      = {1121--1126},\n year       = 2008}\n</code></pre> On the implementation of model predictive control for on-line walking pattern generation <p>paper</p> authorsbibtex <ul> <li>Dimitar Dimitrov</li> <li>Pierre-Brice Wieber</li> <li>Hans Joachim Ferreau</li> <li>Moritz Diehl</li> </ul> <pre><code>@inproceedings{Dimitrov.2008,\n author     = {Dimitrov, Dimitar and Wieber, Pierre-Brice and Ferreau, Hans Joachim and Diehl, Moritz},\n title      = {On the implementation of model predictive control for on-line walking pattern generation},\n booktitle  = {IEEE International Conference on Robotics and Automation (ICRA)},\n pages      = {2685--2690},\n year       = 2008}\n</code></pre>"},{"location":"publications/#2006","title":"2006","text":"On the capture of tumbling satellite by a space robot <p>paper</p> authorsbibtex <ul> <li>Kazuya Yoshida</li> <li>Dimitar Dimitrov</li> <li>Hiroki Nakanishi</li> </ul> <pre><code>@inproceedings{Yoshida.2006,\n author     = {Yoshida, Kazuya and Dimitrov, Dimitar and Nakanishi, Hiroki},\n title      = {On the capture of tumbling satellite by a space robot},\n booktitle  = {IEEE/RSJ International Conference on Intelligent Robots and System (IROS)},\n pages      = {4127--4132},\n year       = 2006}\n</code></pre> Utilization of holonomic distribution control for reactionless path planning <p>paper</p> authorsbibtex <ul> <li>Dimitar Dimitrov</li> <li>Kazuya Yoshida</li> </ul> <pre><code>@inproceedings{Dimitrov.2006,\n author     = {Dimitrov, Dimitar and Yoshida, Kazuya},\n title      = {Utilization of holonomic distribution control for reactionless path planning},\n booktitle  = {IEEE/RSJ International Conference on Intelligent Robots and System (IROS)},\n pages      = {3387--3392},\n year       = 2006}\n</code></pre> Dynamics and control of space manipulators during a satellite capturing operation <p>thesis</p> authorsbibtex <ul> <li>Dimitar Dimitrov<ul> <li>Tohoku University (Japan), Space Robotics Laboratory</li> </ul> </li> </ul> <pre><code>@phdthesis    {Dimitrov.thesis.2006,\n author     = {Dimitrov, Dimitar},\n title      = {Dynamics and control of space manipulators during a satellite capturing operation},\n school     = {Tohoku University},\n year       = 2006}\n</code></pre>"},{"location":"publications/#2005","title":"2005","text":"Utilization of distributed momentum control for planning approaching trajectories of a space manipulator to a target satellite <p>preprint</p> authorsbibtex <ul> <li>Dimitar Dimitrov</li> <li>Kazuya Yoshida</li> </ul> <pre><code>@inproceedings{Dimitrov.2005,\n author     = {Dimitrov, Dimitar and Yoshida, Kazuya},\n title      = {Utilization of distributed momentum control for planning approaching trajectories of a space manipulator to a target satellite},\n booktitle  = {International Symposium on Artificial Intelligence, Robotics and Automation in Space (i-SAIRAS)},\n year       = 2005}\n</code></pre>"},{"location":"publications/#2004","title":"2004","text":"Utilization of the bias momentum approach for capturing a tumbling satellite <p>preprint</p> authorsbibtex <ul> <li>Dimitar Dimitrov</li> <li>Kazuya Yoshida</li> </ul> <pre><code>@inproceedings{Dimitrov.2004b,\n author     = {Dimitrov, Dimitar and Yoshida, Kazuya},\n title      = {Utilization of the bias momentum approach for capturing a tumbling satellite},\n booktitle  = {IEEE/RSJ International Conference on Intelligent Robots and System (IROS)},\n pages      = {3333--3338},\n year       = 2004}\n</code></pre> Momentum distribution in a space manipulator for facilitating the post-impact control <p>preprint</p> authorsbibtex <ul> <li>Dimitar Dimitrov</li> <li>Kazuya Yoshida</li> </ul> <pre><code>@inproceedings{Dimitrov.2004a,\n author     = {Dimitrov, Dimitar and Yoshida, Kazuya},\n title      = {Momentum distribution in a space manipulator for facilitating the post-impact control},\n booktitle  = {IEEE/RSJ International Conference on Intelligent Robots and System (IROS)},\n pages      = {3345--3350},\n year       = 2004}\n</code></pre>"},{"location":"blog/","title":"Posts","text":""},{"location":"blog/202411-summer-walking-challenge/","title":"202411-summer-walking-challenge","text":"<ul> <li><code>data/export_clean.csv</code> is all the data I need (it is a post-processed extract of the   data exported from my iphone).</li> <li><code>img/2024_summer.png</code> do not delete (the rest of the figures can be regenerated)</li> </ul>"},{"location":"blog/202412-python-strings/","title":"202412-python-strings","text":"<p>No artifacts need to be generated here</p> <ul> <li><code>emoji.py</code>: Download and visualize emoji (I just needed to select several nice cases   for the post).</li> <li><code>verify_string_encoding.py</code>: Numerical verification that I have understood PEP393 and   the CPython code (not nice, but had to be done!). In one of his lectures Stephen Boyd   said that sometimes we have to test things in a way we are not prowd of - we should do   it, delete the code and never admit what happened.</li> </ul>"},{"location":"blog/202411-summer-walking-challenge/","title":"Summer walking challenge","text":"<p>Walking has always been an important part of my routine. This summer I decided to collect some data. Here are the results ...</p> <p></p> <p>Figure 1. Daily distance (entire challenge)</p> <p></p> <p>Figure 2. Daily distance (post-challenge)</p> <p></p> <p>Figure 3. Daily distance (last month of challenge)</p> <p></p> <p>Figure 4. Daily step count (last month of challenge)</p>"},{"location":"blog/202411-summer-walking-challenge/#the-challenge","title":"The challenge","text":"<p>On May 21st, I decided to consistently carry my phone with me while walking, not with the intention of walking more than usual, but simply to satisfy my curiosity and track the distance. As it turned out, however, I was on a journey to prove, yet again, the Heisenberg Uncertainty Principle (that observation alters the phenomenon being observed). Before long, I had set targets for myself, and 85 days later, I had walked 1900 km.</p> <p>Figure 1 above shows the distance walked per day (in km), along with the dates when I bought a new pair of walking shoes and when I had to discard them. Figures 3 &amp; 4 zoom in on the final month of the challenge, during which I averaged 28 km per day (roughly 45K steps). It's interesting to observe my pace in the 85 days following the end of the challenge, as shown in Figure 2 (clearly, I couldn't reduce my walking right away).</p> <p>By far the most interesting for me is Figure 5, every point on which represents average distance walked (right axis) and total distance covered (left axis) in the past 31 days. For example, the first point indicates that I have walked 500 km between May 21st and June 20th (which is around 16 km per day on average). The point on August 12th is a summary of what is depicted in Figure 3 and so on. The linear increase in pace is something I didn't aim for. I remember challenging myself to reach, at first, 20 km for the past month, later the target moved to 25 and towards the end 28. I briefly considered pushing for an average of 30 km, but after discarding my walking shoes on August 13th (which, by that point, were in terrible condition), I had difficulty adjusting to a new pair. I also felt tired, so I decided to end the challenge. Adding just two more km per day may not seem like a big deal but, trust me, it requires a level of consistency that's tough to maintain, while my kids kept insisting to go camping. Figure 6 is similar to Figure 5, but the rolling period is one week instead of 31 days (as can be seen, I did manage to hit an average of 30 km per day over the course of a week).</p> <p>Somewhere in the middle of all this, I aimed to cover a marathon distance in a single day, but my daily maximum ended up being around 36 km.</p> <p></p> <p>Figure 5. 31-day rolling distance (entire challenge)</p> <p></p> <p>Figure 6. 7-day rolling distance (entire challenge)</p>"},{"location":"blog/202411-summer-walking-challenge/#a-typical-day","title":"A typical day","text":"<p>I wake up around 6:30 and start the day with about half an hour of reading. Then I stretch and take a few moments to plan what I want to accomplish, aside from my walks. I have breakfast at 7:30, then head out for my first walk of the day at 8:00, which typically lasts about an hour and a half. From 10:00 to 11:00, I focus on other tasks, then have an apple and go for another walk, usually lasting an hour. Lunch is around 12:30 and by 14:00 I'm out again until about 15:00. Afterwards, I take a 30-minute nap and work on other tasks until 17:00 when I have another apple and head out for one more hour. Dinner is around 18:30, followed by my longest walk of the day, which typically lasts about two hours.</p> <p>I mostly walk on flat terrain but occasionally I go hiking. There are three outdoor exercise parks near my place, and I pass by one almost every day. I usually stop to do push-ups and pull-ups, which fit perfectly into my walking routine.</p> <p>All in all, this adds up to between 4 and 7 hours of walking per day.</p>"},{"location":"blog/202411-summer-walking-challenge/#lessons-learned","title":"Lessons learned","text":"<ul> <li>Nutrition plays a key role in sustaining such an effort over time. I had to pay close   attention especially to my protein intake in order to avoid loosing too much weight.   Although I normally don't eat much meat, I found myself craving it daily - and, of   course, I ate.</li> <li>Combining walking with strength training makes me feel amazing - just walking alone   isn't enough.</li> <li>During the challenge I used my bike only once (and I don't own a car), so much like   Forrest Gump, if I was going somewhere - I was walking. This gave me time to reflect   on ideas and communicate with people. Communication while walking is quite a bit more   pleasant for me compared to doing it while e.g., eating at a restaurant.</li> <li>Walking 28 km per day isn't really necessary - 10 to 12 km is probably enough to reap   most of the benefits. However, there's something magical about finding your rhythm   and completely dedicating yourself to it.</li> <li>It is possible to meditate while walking.</li> <li>Overall, I found my early morning walk to be the most beneficial, as it set my mood   for the day, while my after-dinner walk helped me calm down and improved my sleep.</li> <li>Walking helped me with my knees.</li> <li>I found myself walking for three reasons: (1) because I needed it badly, (2) because I   had to go somewhere, and (3) because I wanted to hit a target distance. The latter one   doesn't seem very meaningful now.</li> <li>It would have been better to use at least two pairs of good walking shoes. The ones I   bought weren't well-suited for walking on asphalt.</li> </ul>"},{"location":"blog/202411-summer-walking-challenge/#data","title":"Data","text":"<p>Here is the csv data used to generate the above figures.</p> <p></p>"},{"location":"blog/202412-python-strings/","title":"Anatomy of python strings","text":"<p>From the docs: \"Strings are immutable sequences of Unicode code points\". This requires a bit of unpacking ...</p>"},{"location":"blog/202412-python-strings/#terminology","title":"Terminology","text":"<p>From the sea of technical lingo, I will mostly use three concepts (and often abuse terminology):</p> Symbol <p>A symbol is an entity that conveys meaning in a given context. It can be seen as a \"meme\" in that it represents an idea or recognized concept. For example, it can be a single character or unit of text as perceived by a human reader (regardless of the underlying primitive blocks from which it is formed). The digit <code>1</code> is a symbol, so is that letter <code>\u00e9</code>, and so is the emoji \ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66.</p> Character <p>A primitive building block for symbols. It is common to refer to a visible (i.e., a user-perceived) character as a grapheme.</p> Code point <p>Unicode code points are unsigned integers<sup>1</sup> that map one to one with (primitive) characters. That is, to each character in the Unicode character set there is a corresponding integer code point as its index.</p> <p>For example, the code point <code>97</code> corresponds to the grapheme <code>e</code>. Every (primitive) character can be seen as a symbol, but the opposite is not true because there are many symbols that do not have an assigned code point. That is, some symbols are defined in terms of a sequence of characters (and thus, of code points). Such symbols are commonly referred to as grapheme clusters. An example of a grapheme cluster is \ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66 (as we will see shortly, it consists of 7 characters 4 of which are graphemes).</p>"},{"location":"blog/202412-python-strings/#redundancy-of-representation","title":"Redundancy of representation","text":"<pre><code>flowchart LR\n    subgraph G0 [symbol]\n        symbol{\"\u00e9\"}\n    end\n    subgraph G1 [as one code point]\n        one_code_point[\"\u00e9 (U+00E9)\"]\n    end\n    subgraph G2 [as two code points]\n        dispatch@{ shape: framed-circle }\n        dispatch --&gt; two_code_point_1[\"e (U+0065)\"]\n        dispatch --&gt; two_code_point_2[\"\u0301  (U+0301)\"]\n    end\n    symbol --&gt; dispatch\n    symbol --&gt; one_code_point\n\n    style symbol font-size:20px\n    style one_code_point font-size:18px\n    style two_code_point_1 font-size:18px\n    style two_code_point_2 font-size:18px</code></pre> <p>In Unicode, the symbol \u00e9 can be encoded in two ways (see Unicode equivalence). First, it has a dedicated code point (which defines it as a \"primitive\" grapheme). Second, it can be represented as a combination of e and an acute accent (which makes it a grapheme cluster as well).</p> <pre><code>s1 = \"\u00e9\"  # using one code point (U+00E9)\ns2 = \"e\u0301\"  # using two code points (equivalent to s2 = \"e\\u0301\")\n\nassert s1 != s2\nassert len(s1) == 1\nassert len(s2) == 2\n\nfor char in s2:\n    code_point = ord(char)\n    print(f\"{code_point} ({hex(code_point)})\")\n</code></pre> <p>Output: (1)</p> <ol> <li> <p><code>M-x describe-char</code> in <code>emacs</code> gives:</p> on \u00e9 (one code point)on e\u0301 (two code points) <pre><code>             position: 1 of 1 (0%), column: 0\n            character: \u00e9 (displayed as \u00e9) (codepoint 233, #o351, #xe9)\n              charset: iso-8859-1 (Latin-1 (ISO/IEC 8859-1))\ncode point in charset: 0xE9\n               script: latin\n               syntax: w    which means: word\n             category: .:Base, L:Strong L2R, c:Chinese, j:Japanese, l:Latin, v:Viet\n             to input: type \"C-x 8 RET e9\" or \"C-x 8 RET LATIN SMALL LETTER E WITH ACUTE\"\n          buffer code: #xC3 #xA9\n            file code: #xC3 #xA9 (encoded by coding system utf-8-unix)\n              display: terminal code #xC3 #xA9\n\nCharacter code properties: customize what to show\n  name: LATIN SMALL LETTER E WITH ACUTE\n  old-name: LATIN SMALL LETTER E ACUTE\n  general-category: Ll (Letter, Lowercase)\n  decomposition: (101 769) ('e' ' ')\n</code></pre> <pre><code>             position: 1 of 2 (0%), column: 0\n            character: e (displayed as e) (codepoint 101, #o145, #x65)\n              charset: ascii (ASCII (ISO646 IRV))\ncode point in charset: 0x65\n               script: latin\n               syntax: w    which means: word\n             category: .:Base, L:Strong L2R, a:ASCII, l:Latin, r:Roman\n             to input: type \"C-x 8 RET 65\" or \"C-x 8 RET LATIN SMALL LETTER E\"\n          buffer code: #x65\n            file code: #x65 (encoded by coding system utf-8-unix)\n              display: composed to form \"e \" (see below)\n\nComposed with the following character(s) \" \" by these characters:\n e (#x65) LATIN SMALL LETTER E\n   (#x301) COMBINING ACUTE ACCENT\n\nCharacter code properties: customize what to show\n  name: LATIN SMALL LETTER E\n  general-category: Ll (Letter, Lowercase)\n  decomposition: (101) ('e')\n</code></pre> </li> </ol> <pre><code>101 (0x65)\n769 (0x301)\n</code></pre>"},{"location":"blog/202412-python-strings/#example-a-family","title":"Example: a family","text":"<pre><code>flowchart TD\n    %%{init: {'themeVariables': {'title': 'My Flowchart Title'}}}%%\n    family1[\"\ud83d\udc69\u200d\ud83d\udc67\"]\n    family2[\"\ud83d\udc69\u200d\ud83d\udc69\u200d\ud83d\udc67\"]\n    family3[\"\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66\"]\n    family4[\"\ud83d\udc6a\ufe0e\"]\n    family5[\"\ud83d\udc68\u200d\ud83d\udc66\u200d\ud83d\udc66\"]\n    C@{ shape: framed-circle, label: \"Stop\" }\n    C --&gt; cp1[\"\ud83d\udc68\"]\n    C --&gt; cp2[\"U+200d\"]\n    C --&gt; cp3[\"\ud83d\udc69\"]\n    C --&gt; cp4[\"U+200d\"]\n    C --&gt; cp5[\"\ud83d\udc67\"]\n    C --&gt; cp6[\"U+200d\"]\n    C --&gt; cp7[\"\ud83d\udc66\"]\n    family3 --&gt; C\n\n    cp1-.-&gt;cp1-hex[\"U+1f468\"]\n    cp3-.-&gt;cp3-hex[\"U+1f469\"]\n    cp5-.-&gt;cp5-hex[\"U+1f467\"]\n    cp7-.-&gt;cp7-hex[\"U+1f466\"]\n\n    style family1 font-size:50px\n    style family2 font-size:50px\n    style family3 font-size:50px\n    style family4 font-size:50px\n    style family5 font-size:50px\n    style cp1 font-size:30px\n    style cp2 font-size:30px\n    style cp3 font-size:30px\n    style cp4 font-size:30px\n    style cp5 font-size:30px\n    style cp6 font-size:30px\n    style cp7 font-size:30px\n    style cp1-hex font-size:30px\n    style cp3-hex font-size:30px\n    style cp5-hex font-size:30px\n    style cp7-hex font-size:30px</code></pre> <p>There are various emoji symbols that portray a family. They have different semantics, which is reflected by the code points used to form them. In the representation of the middle one (depicted on the lower levels), there are 4 primitive graphemes glued together with the zero-width joiner character <code>U+200d</code>. We can use <code>list(\"\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66\")</code> to get a list of characters associated with the code points that form \ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66.</p>"},{"location":"blog/202412-python-strings/#indexing","title":"Indexing","text":"<p>Consider the string <code>sentense = \"This \ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66 is my family!\"</code>. As python strings are (stored as) sequences of code points, <code>sentense[:6]</code> would give <code>\"This \ud83d\udc68\"</code> because \ud83d\udc68 corresponds to the first (also called a base) code point of \ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66. As can be expected <code>sentense[:8]</code> returns <code>\"This\ud83d\udc68\u200d\ud83d\udc69\"</code>, where the zero-width joiner is not visible<sup>2</sup>.</p> <p>The situation can get tricky with symbols that may have different Unicode representations. For example <code>len(\"L'id\u00e9e a \u00e9t\u00e9 r\u00e9\u00e9valu\u00e9e.\")</code> is 23, while <code>len(\"L'ide\u0301e a e\u0301te\u0301 re\u0301e\u0301value\u0301e.\")</code> is 29 because all symbols e\u0301 in the latter string are encoded using two code points. One can imagine strings with a mix of representations for the same symbols which can be difficult to handle in an ad hoc manner.</p>"},{"location":"blog/202412-python-strings/#grapheme-clustering","title":"Grapheme clustering","text":"<p>The Unicode standard defines rules for identifying sequences of code points that are meant to form a particular symbol (i.e., grapheme cluster). Finding symbol boundaries is a common problem e.g., in text editors and terminal emulators. As an example, consider the following functionality from the <code>grapheme</code><sup>3</sup> package:</p> <pre><code>import grapheme\n\nsentense = \"This \ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66 is my family!\"\n\nassert len(sentense) == 26\nassert grapheme.length(sentense) == 20\nassert not grapheme.startswith(sentense, sentense[:6])\n</code></pre>"},{"location":"blog/202412-python-strings/#normalization","title":"Normalization","text":"<p>The <code>unicodedata</code> package is a part of python's standard library and can be used to normalize a string. That is, to detect symbols for which alternative Unicode encodings exist and to convert them to a given canonical form.</p> <pre><code>import unicodedata\n\ns1 = \"L'id\u00e9e a \u00e9t\u00e9 r\u00e9\u00e9valu\u00e9e.\"\nassert len(s1) == 23\n\n# each \"\u00e9\" becomes \"e\\u0301\"\ns2 = unicodedata.normalize(\"NFD\", s1) # canonical decomposition\nassert len(s2) == 29 # (1)!\n\ns3 = unicodedata.normalize(\"NFC\", s2) # canonical composition\nassert len(s3) == 23\nassert s1 == s3\nassert s1 != s2\n</code></pre> <ol> <li>While the representation of symbols resulting from the <code>NDF</code> canonical decomposition     may contain more code points, it allows for greater flexibility of text processing     in many contexts, e.g., string pattern matching.</li> </ol>"},{"location":"blog/202412-python-strings/#memory-footprint","title":"Memory footprint","text":"<p>The above discussion is mostly abstract in that it makes no assumptions on how code points (ranging from <code>0</code> to <code>1114111</code>) are to be stored in memory. Starting from PEP 393, python addresses the memory storage problem in a pragmatic way by handling four cases which depend only on one parameter: the largest code point occurring in the string.</p> <pre><code>import sys\nimport unicodedata\n\ns1 = \"L'id\u00e9e a \u00e9t\u00e9 r\u00e9\u00e9valu\u00e9e.\"\ns2 = unicodedata.normalize(\"NFD\", s1)\n\nm1, m2 = max(s1), max(s2)\nprint(f\"[s1]: {ord(m1)} ( {m1} ) #bytes = {sys.getsizeof(s1)}\")\nprint(f\"[s2]: {ord(m2)} ( {m2}  ) #bytes = {sys.getsizeof(s2)}\")\n</code></pre> <p>Output:</p> <pre><code>[s1]: 233 ( \u00e9 ) #bytes = 80\n[s2]: 769 ( \u0301  ) #bytes = 116\n</code></pre> <p>The largest code point for the <code>s2</code> string corresponds to the combining acute accent, while for the <code>s1</code> string it corresponds to <code>\u00e9</code>.</p> <p>The four cases are:  </p> <p>where  denotes the largest code point in the string . The memory required to store  is</p> <p> </p> <p>where  is the number of code points in  and, the size of the <code>C-struct</code> that holds the data is given by<sup>4</sup></p> <p> </p> <p>The above logic is implemented in the <code>string_bytes</code> function below<sup>5</sup>.</p> <code>def string_bytes(s):</code> <pre><code>def string_bytes(s):\n    numb_code_points, max_code_points = len(s), ord(max(s))\n\n    # C-structs in cpython/Objects/unicodeobject.c\n    # ----------------------------------------------\n    # ASCII     (use PyASCIIObject):\n    #   2 x ssize_t       = 16\n    #   6 x unsigned int  = 24\n    # otherwise (use PyCompactUnicodeObject):\n    #   1 x PyASCIIObject = 40\n    #   1 x ssize_t       = 8\n    #   1 x char *        = 8\n    # assuming a x86_64 architecture\n    struct_bytes = 56\n    if max_code_points &lt; 2**7:\n        code_point_bytes = 1\n        struct_bytes = 40\n    elif max_code_points &lt; 2**8:\n        code_point_bytes = 1\n    elif max_code_points &lt; 2**16:\n        code_point_bytes = 2\n    else:\n        code_point_bytes = 4\n\n    # `+ 1` for zero termination\n    # the result is identical with sys.getsizeof(s)\n    return struct_bytes + (numb_code_points + 1) * code_point_bytes\n</code></pre> <p>For the above example, <code>s1</code> is <code>56 + (23 + 1) * 1 = 80</code> bytes because it falls in the second case as its largest code point is 233. The string <code>s2</code>, on the other hand, falls in the third case because the acute accent has a code point above 255 (so its size is <code>56 + (29 + 1) * 2 = 116</code> bytes).</p> <p>Three clear advantages of the PEP 393 approach:</p> <ul> <li>an optimized ASCII implementation can be used for the most common (ASCII) case</li> <li>the constant number of bytes per code point<sup>6</sup> results   in constant-time indexing and facilitates other operations</li> <li>can handle natively strings containing non-BMP   characters, i.e., code points greater   than .</li> </ul> <p>On the flip-side, concatenating a single emoji to an ASCII string increases the size x 4.</p>"},{"location":"blog/202412-python-strings/#code-units","title":"Code units","text":"<p>The building block used to actually store a code point in memory is often called a code unit. For example, consider the acute accent (<code>U+0301</code>):</p> <pre><code>flowchart TD\n    %%{init: {'themeVariables': {'title': 'My Flowchart Title'}}}%%\n\n    s[\"U+0301\"]\n    s --&gt; utf8[\"UTF-8\"]\n    s --&gt; utf16[\"UTF-16\"]\n    s --&gt; utf32[\"UTF-32\"]\n\n    C@{ shape: framed-circle, label: \"Stop\" }\n    C -.-&gt; utf8-1[\"CC\"]\n    C -.-&gt; utf8-2[\"81\"]\n\n    utf8 -.-&gt; C\n    utf16 -.-&gt; utf16-1[\"0103\"]\n    utf32 -.-&gt; utf16-2[\"01030000\"]\n\n    style utf8 stroke-width:2px,stroke-dasharray: 5 5\n    style utf16 stroke-width:2px,stroke-dasharray: 5 5\n    style utf32 stroke-width:2px,stroke-dasharray: 5 5</code></pre> <ul> <li>with a <code>utf-8</code> encoding there are two 8-bit code units (<code>0xCC</code> and <code>0x81</code>)</li> <li>with a <code>utf-16</code> encoding there is one 16-bit code unit</li> <li>with a <code>utf-32</code> encoding there is one 32-bit code unit .</li> </ul> <p>Note that, in the above example, the code units for <code>utf-16</code> and <code>utf-32</code> are stored using little-endian.</p>"},{"location":"blog/202412-python-strings/#four-string-encodings","title":"Four string encodings","text":"<p>A different encoding is used in each of the four cases discussed above.</p> <ul> <li>case 1 : ASCII (which is equivalent to UTF-8 in this range)</li> <li>case 2 : UCS1 (i.e., LATIN-1)</li> <li>case 3 : UCS2 (i.e., UTF-16)</li> <li>case 4 : UCS4 (i.e., UTF-32).</li> </ul> <p>For example, the string <code>mess</code> in the snippet below has 8 code points and , hence we are in case 3 in which UTF-16 encoding should be used. At the end, the encoding computed manually is compared<sup>7</sup> with the actual memory occupied by our string.</p> <pre><code>mess = \"I\u2665\ufe0f\u65e5\u672c\u0413\u041e\u00a9\"\n\nassert len(mess) == 8\nassert ord(max(mess)) == 65039  # case 3: 255 &lt; 65039 &lt; 65536\n\n# utf-16-le stands for utf-16 with little-endian\nencoding = b''.join([char.encode(\"utf-16-le\") for char in mess]).hex()\n\nassert string_bytes(mess) == 74  # 56 + (8 + 1) * 2\nassert len(encoding) == 32  # i.e., 16 bytes as it is in hex\nassert encoding == \"490065260ffee5652c6713041e04a900\"\n\n# --------------------------------------------------------------------------\n# compare to groundtruth (this is a hack!)\n# --------------------------------------------------------------------------\nimport ctypes\nimport sys\n\ndef memory_dump(string):\n    address = id(string)  # assuming CPython\n    buffer = (ctypes.c_char * sys.getsizeof(string)).from_address(address)\n    return bytes(buffer)\n\n# [56:] removes what we called struct_bytes above (in CPython they come first)\n# [:-2] removes the zero termination bytes\nassert memory_dump(mess)[56:-2].hex() == encoding\n# --------------------------------------------------------------------------\n</code></pre>"},{"location":"blog/202412-python-strings/#bytes-objects","title":"Bytes objects","text":"<p>As we have seen, the code units used to store a python string in memory depend on the string itself and are abstracted away from the user. While this is a good thing in many cases, sometimes we need more fine-grained control. To this end, python provides the \"bytes\" object (an immutable sequences of single bytes). Actually we already used it in the previous example as it is the return type of <code>str.encode</code>.</p> <p>Let us consider the string <code>a_man = \"a\ud83d\udc68\"</code>. By now we know that it is stored using 4 bytes per code point. Using <code>a_man.encode(\"utf-32\")</code> we obtain:</p> <ul> <li><code>\"a\"</code>: <code>97, 0, 0, 0</code></li> <li><code>\"\ud83d\udc68\"</code>: <code>104, 244, 1, 0</code>.</li> </ul> <p>If we relax the constraint of constant number of bytes per code point, we can dedicate less space to our string. Using <code>a_man.encode(\"utf-16\")</code> we obtain:</p> <ul> <li><code>\"a\"</code>: <code>97, 0</code></li> <li><code>\"\ud83d\udc68\"</code>: <code>61, 216, 104, 220</code></li> </ul> <p>or using <code>a_man.encode(\"utf-8\")</code>:</p> <ul> <li><code>\"a\"</code>: <code>97</code></li> <li><code>\"\ud83d\udc68\"</code>: <code>240, 159, 145, 168</code>.</li> </ul> <p>All above representations have their applications. For example UTF-8 provides compatibility with ASCII and efficient data storage, while UTF-16 and UTF-32 allow for faster processing of a larger range of characters. Having the possibility to easily/efficiently change representations is convenient.</p> <p>Bytes do not necessarily have to be associated with individual code points, as is the case when using <code>str.encode</code>. For example, suppose we want to express the string <code>\"a1b1\"</code> as a byte object, where each pair of characters represents a byte in hex (i.e., <code>0xA1</code> followed by <code>0xB1</code>). In this case, using <code>list(\"a1b1\".encode())</code> is not appropriate, as it would return <code>[97, 49, 98, 49]</code>, which are the ASCII codes for the characters <code>a</code>, <code>1</code>, <code>b</code>, and <code>1</code>, respectively. Instead, we should consider the additional structure and use <code>list(bytes.fromhex(\"a1b1\"))</code>, which results in <code>[161, 177]</code>.</p> <p>Bytes objects can also be used in other contexts. For instance, <code>(1).to_bytes(4, byteorder='little')</code> returns the byte representation of the integer 1 (in little-endian).</p>"},{"location":"blog/202412-python-strings/#immutability","title":"Immutability","text":"<p>The design decision to have immutable string in python has far-reaching implication related to e.g., hashing, performance optimizations, garbage collection, thread safety etc. In addition to all this, having immutable strings was a prerequisite for the approach in PEP 393.</p> <ol> <li> <p>Often expressed as a hexadecimal number.\u00a0\u21a9</p> </li> <li> <p>The string might be rendered as <code>\"This \ud83d\udc68\\u200d\ud83d\udc69\"</code>.\u00a0\u21a9</p> </li> <li> <p><code>pip install grapheme</code> \u21a9</p> </li> <li> <p>Assuming a <code>x86_64</code> architecture (see the <code>string_bytes</code> function for more details).\u00a0\u21a9</p> </li> <li> <p>Based on <code>PyObject * PyUnicode_New(Py_ssize_t size, Py_UCS4 maxchar)</code> in <code>unicodeobject.c</code>.\u00a0\u21a9</p> </li> <li> <p>The smallest possible is always chosen.\u00a0\u21a9</p> </li> <li> <p>We used a <code>CPython</code> implementation of <code>python 3.12</code>.\u00a0\u21a9</p> </li> </ol>"},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/category/python/","title":"python","text":""},{"location":"blog/category/sports/","title":"sports","text":""}]}